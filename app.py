import streamlit as st
import google.generativeai as genai
from streamlit_mic_recorder import mic_recorder
from PIL import Image

# --- CONFIGURATION ---
st.set_page_config(page_title="Nihongo Coach", page_icon="ğŸ‡¯ğŸ‡µ")

st.markdown("<style>#MainMenu {visibility: hidden;} footer {visibility: hidden;} header {visibility: hidden;} .stDeployButton {display:none;}</style>", unsafe_allow_html=True)

# --- SYSTÃˆME DE CONNEXION DOUBLE CLÃ‰ ---
def get_model():
    # Liste des clÃ©s disponibles dans tes secrets
    keys = []
    if "GEMINI_API_KEY" in st.secrets:
        keys.append(st.secrets["GEMINI_API_KEY"])
    if "GEMINI_API_KEY_2" in st.secrets:
        keys.append(st.secrets["GEMINI_API_KEY_2"])

    # On essaie la premiÃ¨re clÃ©, si elle sature, on passe Ã  la seconde
    for i, key in enumerate(keys):
        try:
            genai.configure(api_key=key)
            model = genai.GenerativeModel('gemini-3-flash-preview')
            # Test lÃ©ger pour vÃ©rifier si la clÃ© rÃ©pond
            model.generate_content("test", generation_config={"max_output_tokens": 1})
            return model, i + 1
        except Exception:
            if i == len(keys) - 1: # Si c'est la derniÃ¨re clÃ© et qu'elle Ã©choue
                return None, 0
            continue
    return None, 0

# Initialisation du modÃ¨le
model, key_index = get_model()

if not model:
    st.error("ğŸš« Toutes vos clÃ©s API sont saturÃ©es. Attendez 1 minute.")
    st.stop()
else:
    # Petit indicateur discret pour savoir quelle clÃ© est utilisÃ©e
    st.caption(f"ConnectÃ© via ClÃ© #{key_index}")

# Initialisation de la mÃ©moire
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "texte_lu" not in st.session_state:
    st.session_state.texte_lu = ""

st.title("ğŸ‡¯ğŸ‡µ Mon Coach Japonais")

# --- SECTION 1 : SCANNER ---
st.subheader("1. Ma LeÃ§on")
fichier = st.file_uploader("Photo du cours", type=['png', 'jpg', 'jpeg'])

if fichier:
    img = Image.open(fichier)
    if st.button("ğŸ“· Analyser l'image"):
        with st.spinner("Lecture du texte..."):
            try:
                res = model.generate_content([
                    "Extrais le texte japonais. Format : 1. Japonais (Kanjis/Kanas) 2. Romaji. Pas de franÃ§ais.", 
                    img
                ])
                st.session_state.texte_lu = res.text
                st.success("Lecture terminÃ©e !")
            except Exception as e:
                st.error("Erreur technique. RÃ©essayez dans un instant.")

if st.session_state.texte_lu:
    st.markdown("### ğŸ“ Texte Extrait")
    st.info(st.session_state.texte_lu)

    # --- SECTION 2 : PRATIQUE ORALE ---
    st.divider()
    st.subheader("2. Pratique Orale")
    audio = mic_recorder(start_prompt="ğŸ¤ Lire le texte", stop_prompt="ğŸ›‘ Analyser mon accent", key='recorder_lecture')

    if audio:
        with st.spinner("Analyse du Sensei..."):
            try:
                audio_part = {"mime_type": "audio/wav", "data": audio['bytes']}
                prompt_accent = f"Analyse cet audio pour le texte : '{st.session_state.texte_lu}'. Note/10 et conseils en FranÃ§ais."
                feedback = model.generate_content([prompt_accent, audio_part])
                st.markdown("#### ğŸ’¡ Feedback")
                st.write(feedback.text)
            except:
                st.warning("Quota atteint. RÃ©essayez dans 30 secondes.")

    # --- SECTION 3 : DIALOGUE ---
    st.divider()
    st.subheader("3. Dialogue d'immersion")
    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    audio_chat = mic_recorder(start_prompt="ğŸ¤ RÃ©pondre", stop_prompt="ğŸ›‘ Envoyer", key='recorder_chat')

    if audio_chat:
        with st.spinner("RÃ©flexion..."):
            try:
                audio_msg = {"mime_type": "audio/wav", "data": audio_chat['bytes']}
                prompt_ctx = f"Tu es prof. On parle de : {st.session_state.texte_lu}. RÃ©ponds en Japonais+Romaji uniquement."
                # On limite l'historique aux 2 derniers messages pour Ã©conomiser les ressources
                response = model.generate_content([prompt_ctx] + [msg["content"] for msg in st.session_state.chat_history[-2:]] + [audio_msg])
                st.session_state.chat_history.append({"role": "user", "content": "ğŸ¤ (Vocal)"})
                st.session_state.chat_history.append({"role": "assistant", "content": response.text})
                st.rerun()
            except:
                st.error("Le Sensei a besoin d'une pause (Quota).")

    if st.button("ğŸ”„ Nouveau dialogue"):
        st.session_state.chat_history = []
        st.rerun()
