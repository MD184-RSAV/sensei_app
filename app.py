import streamlit as st
import google.generativeai as genai
from streamlit_mic_recorder import mic_recorder
from PIL import Image

# --- CONFIGURATION ---
st.set_page_config(page_title="Nihongo Coach", page_icon="ğŸ‡¯ğŸ‡µ")

# Masquage Streamlit
st.markdown("<style>#MainMenu {visibility: hidden;} footer {visibility: hidden;} header {visibility: hidden;} .stDeployButton {display:none;}</style>", unsafe_allow_html=True)

# --- CONNEXION ---
if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
else:
    st.error("ClÃ© API manquante dans les Secrets.")

model = genai.GenerativeModel('gemini-3-flash-preview')

# Initialisation de la mÃ©moire
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "texte_lu" not in st.session_state:
    st.session_state.texte_lu = ""

st.title("ğŸ‡¯ğŸ‡µ Mon Coach Japonais")

# --- SECTION 1 : SCANNER ---
st.subheader("1. Ma LeÃ§on")
fichier = st.file_uploader("Photo du cours", type=['png', 'jpg', 'jpeg'])

if fichier:
    img = Image.open(fichier)
    if st.button("ğŸ“· Analyser l'image"):
        with st.spinner("Lecture..."):
            res = model.generate_content(["Extrais le texte japonais/romaji de cette image.", img])
            st.session_state.texte_lu = res.text

if st.session_state.texte_lu:
    with st.expander("ğŸ“– Voir le texte extrait", expanded=False):
        st.write(st.session_state.texte_lu)

    # --- SECTION 2 : ANALYSE ORALE (AVEC CONSEILS EN FRANÃ‡AIS) ---
    st.subheader("2. Pratique Orale")
    audio = mic_recorder(start_prompt="ğŸ¤ Lire le texte", stop_prompt="ğŸ›‘ Analyser mon accent", key='recorder_lecture')

    if audio:
        with st.spinner("Analyse du Sensei..."):
            audio_part = {"mime_type": "audio/wav", "data": audio['bytes']}
            # Ici, on autorise le franÃ§ais pour la pÃ©dagogie
            prompt_accent = f"""
            Analyse mon audio pour ce texte : '{st.session_state.texte_lu}'. 
            1. Donne une note sur 10.
            2. Donne des conseils de prononciation dÃ©taillÃ©s EN FRANÃ‡AIS pour m'aider Ã  m'amÃ©liorer.
            """
            feedback = model.generate_content([prompt_accent, audio_part])
            st.info(feedback.text)

    # --- SECTION 3 : DIALOGUE INTERACTIF (IMMERSION JAPONAIS/ROMAJI) ---
    st.divider()
    st.subheader("3. Dialogue d'immersion")
    st.write("Ici, le Sensei ne parle que japonais !")
    
    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    audio_chat = mic_recorder(start_prompt="ğŸ¤ RÃ©pondre au Sensei", stop_prompt="ğŸ›‘ Envoyer", key='recorder_chat')

    if audio_chat:
        with st.spinner("Le Sensei rÃ©flÃ©chit..."):
            audio_msg = {"mime_type": "audio/wav", "data": audio_chat['bytes']}
            
            # Ici, interdiction du franÃ§ais pour le flux de conversation
            prompt_context = f"""
            Tu es un prof de japonais. On discute autour de ce texte : {st.session_state.texte_lu}. 
            RÃ©ponds Ã  l'Ã©lÃ¨ve et pose-lui une question simple.
            RÃˆGLE : Interdiction d'utiliser le franÃ§ais. 
            RÃ©ponds uniquement en Japonais (Kanji/Kana) avec le RÅmaji juste en dessous.
            """
            
            response = model.generate_content([prompt_context] + [msg["content"] for msg in st.session_state.chat_history] + [audio_msg])
            
            st.session_state.chat_history.append({"role": "user", "content": "ğŸ¤ (Message vocal)"})
            st.session_state.chat_history.append({"role": "assistant", "content": response.text})
            
            st.rerun()

    if st.button("ğŸ”„ Nouveau dialogue"):
        st.session_state.chat_history = []
        st.rerun()
